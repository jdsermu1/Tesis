def warn(*args, **kwargs):
    pass
    
import warnings
warnings.warn = warn
    
class MyBalancedDataGenerator(Sequence):
    def __init__(self, directory_iterator, batch_size, image_shape):
        self.directory_iterator = directory_iterator
        self.batch_size = batch_size
        self.image_shape = image_shape
        
    
    def __len__(self):
        return self.directory_iterator.__len__()
        
    def __getitem__(self, idx):
        x, y = self.directory_iterator.next()
        if not np.sum(np.sum(y, axis=0)==y.shape[0]):
            generator, _ = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), 
                                                    batch_size=self.batch_size, 
                                                    keep_sparse=True)
            x_processed, y_processed = generator.__next__()
            x_processed = x_processed.reshape(-1, *self.image_shape)
            return x_processed, y_processed
        else:
            return x, y
            
# count = 0
for (x,y) in train_flow:
    x_t, y_t = x, y
    break
gen, steps_per_epoch = balanced_batch_generator(x_t.reshape(x_t.shape[0], -1), y_t, sampler=RandomOverSampler(), batch_size=batch_size, keep_sparse=True)
x_f, y_f = gen.__next__()
x_f = x_f.reshape(-1, 540,540,3)
print(y)
print(y_f)


class BalancedDataGenerator(Sequence):
    def __init__(self, x, y, datagen, batch_size=32):
        self.datagen = datagen
        self.batch_size = min(batch_size, x.shape[0])
        datagen.fit(x)
        self.gen, self.steps_per_epoch = balanced_batch_generator(x.reshape(x.shape[0], -1), 
                                                                  y, 
                                                                  sampler=RandomOverSampler(), 
                                                                  batch_size=self.batch_size, 
                                                                  keep_sparse=True)
        self._shape = (self.steps_per_epoch * batch_size, *x.shape[1:])
        
    def __len__(self):
        return self.steps_per_epoch

    def __getitem__(self, idx):
        x_batch, y_batch = self.gen.__next__()
        x_batch = x_batch.reshape(-1, *self._shape[1:])
        return self.datagen.flow(x_batch, y_batch, batch_size=self.batch_size).next()






class MyBalancedDataGenerator(Sequence):
    def __init__(self, directory_iterator, batch_size, image_shape):
        self.directory_iterator = directory_iterator
        self.batch_size = batch_size
        self.image_shape = image_shape
        
    
    def __len__(self):
        return self.directory_iterator.__len__()
        
    def __getitem__(self, idx):
        x, y = self.directory_iterator.next()
        if not np.sum(np.sum(y, axis=0)==y.shape[0]):
            generator, _ = balanced_batch_generator(x.reshape(x.shape[0], -1), y, sampler=RandomOverSampler(), 
                                                    batch_size=self.batch_size, 
                                                    keep_sparse=True)
            x_processed, y_processed = generator.__next__()
            x_processed = x_processed.reshape(-1, *self.image_shape)
            return x_processed, y_processed
        else:
            return x, y
        


my_train_flow = MyBalancedDataGenerator(directory_iterator=train_flow, batch_size=batch_size, image_shape=(540, 540, 3))
