{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change this w.r.t data\n",
    "# dir_path = '../../data/train2017_hard'\n",
    "dir_path = '../DR Databases/Kaggle/strategy 1'\n",
    "# num_classes = 80\n",
    "num_classes = 5\n",
    "folders = ['train']\n",
    "#num_images_train = 117266\n",
    "num_images_train = 80000\n",
    "load_data_using = 'tfdata'\n",
    "batch_size = 50\n",
    "img_dims = [540, 540]\n",
    "epochs = 5\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data_using_keras(folders):\n",
    "    \"\"\"\n",
    "    Load the images in batches using Keras.\n",
    "    Shuffle images (for training set only) using keras.\n",
    "    Returns:\n",
    "    Data Generator to be used while training the model.\n",
    "    Note: Keras might need 'pillow' library to be installed. Use-\n",
    "    # pip install pillow\n",
    "    \"\"\"\n",
    "    image_generator = {}\n",
    "    data_generator = {}\n",
    "    for x in folders:\n",
    "        image_generator[x] = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        shuffle_images = True if x == 'train' else False\n",
    "\n",
    "        data_generator[x] = image_generator[x].flow_from_directory(\n",
    "            batch_size=batch_size,\n",
    "            directory=os.path.join(dir_path, x),\n",
    "            shuffle=shuffle_images,\n",
    "            target_size=(img_dims[0], img_dims[1]),\n",
    "            class_mode='categorical')\n",
    "\n",
    "    return data_generator\n",
    "\n",
    "def load_data_using_tfdata(folders):\n",
    "    \"\"\"\n",
    "    Load the images in batches using Tensorflow (tfdata).\n",
    "    Cache can be used to speed up the process.\n",
    "    Faster method in comparison to image loading using Keras.\n",
    "    Returns:\n",
    "    Data Generator to be used while training the model.\n",
    "    \"\"\"\n",
    "    def parse_image(file_path):\n",
    "        # convert the path to a list of path components\n",
    "        parts = tf.strings.split(file_path, os.path.sep)\n",
    "        class_names = np.array(os.listdir(dir_path + '/train'))\n",
    "        # The second to last is the class-directory\n",
    "        label = parts[-2] == class_names\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        # convert the compressed string to a 3D uint8 tensor\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        # Use `convert_image_dtype` to convert to floats in the [0,1] range\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        # resize the image to the desired size.\n",
    "        img = tf.image.resize(img, [img_dims[0], img_dims[1]])\n",
    "        return img, label\n",
    "\n",
    "    def prepare_for_training(ds, cache='./cache_dump', shuffle_buffer_size=1):\n",
    "        # If a small dataset, only load it once, and keep it in memory.\n",
    "        # use `.cache(filename)` to cache preprocessing work for datasets\n",
    "        # that don't fit in memory.\n",
    "        if cache:\n",
    "            if isinstance(cache, str):\n",
    "                ds = ds.cache(cache)\n",
    "            else:\n",
    "                ds = ds.cache()\n",
    "        ds = ds.cache(cache)\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "        # Repeat forever\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.batch(batch_size)\n",
    "        # `prefetch` lets the dataset fetch batches in the background\n",
    "        # while the model is training.\n",
    "        ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "        return ds\n",
    "\n",
    "    data_generator = {}\n",
    "    for x in folders:\n",
    "        dir_extend = dir_path + '/' + x\n",
    "        list_ds = tf.data.Dataset.list_files(glob.glob(os.path.join(dir_extend, \"**\", '*.jpeg')))\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        # Set `num_parallel_calls` so that multiple images are\n",
    "        # processed in parallel\n",
    "        labeled_ds = list_ds.map(parse_image, num_parallel_calls=AUTOTUNE)\n",
    "        # cache = True, False, './file_name'\n",
    "        # If the dataset doesn't fit in memory use a cache file,\n",
    "        # eg. cache='./data.tfcache'\n",
    "        data_generator[x] = prepare_for_training(labeled_ds)\n",
    "\n",
    "    return data_generator\n",
    "\n",
    "\n",
    "def timeit(ds, steps=1000):\n",
    "        \"\"\"\n",
    "        Check performance/speed for loading images using Keras or tfdata.\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        it = iter(ds)\n",
    "        for i in range(steps):\n",
    "            x, y = next(it)\n",
    "#             if(i==0):\n",
    "#                 print(x.shape, y.shape)\n",
    "            print('   >> ', i, f'/{str(steps)}', end='\\r')\n",
    "        duration = time.time()-start\n",
    "        print(f'''{steps} batches: '''\n",
    "                f'''{datetime.timedelta(seconds=int(duration))}''')\n",
    "        print(batch_size*steps)\n",
    "        print(f'{round(batch_size*steps/duration)} Images/s')\n",
    "\n",
    "\n",
    "def train_model(data_generator):\n",
    "    \"\"\"\n",
    "    Create and train model to perform Transfer learning using pretrained models.\n",
    "    Base layers of pretrained models are freezed.\n",
    "    Stack the classification layers on top of the pretrained model.\n",
    "    \"\"\"\n",
    "    img_shape = (img_dims[0], img_dims[1], 3)\n",
    "\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "            input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "    # Freeze the base layers of pretrained model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([base_model,\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(\n",
    "                                        256, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(num_classes)])\n",
    "\n",
    "    # Define parameters for model compilation\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        data_generator['train'],\n",
    "        steps_per_epoch=num_images_train // batch_size,\n",
    "        epochs=epochs,\n",
    "        )\n",
    "\n",
    "    time_elapsed = time.time()-since\n",
    "    print(f'''\\nTraining time: '''\n",
    "                f'''{datetime.timedelta(seconds=int(time_elapsed))}''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 540, 540, 3), (None, 5)), types: (tf.float32, tf.bool)>\n",
      "   >>  61 /1000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-79c03ffd7ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# train_model(data_generator)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-53ac28aa346c>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(ds, steps)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;31m#             if(i==0):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m#                 print(x.shape, y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/main_env/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/main_env/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/main_env/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2574\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   2575\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2576\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2577\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if load_data_using == 'keras':\n",
    "    data_generator = load_data_using_keras(folders)\n",
    "elif load_data_using == 'tfdata':\n",
    "    data_generator = load_data_using_tfdata(folders)\n",
    "\n",
    "    \n",
    "print(data_generator['train'])\n",
    "timeit(data_generator['train'])\n",
    "\n",
    "# train_model(data_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
